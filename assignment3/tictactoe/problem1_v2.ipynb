{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207f7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386923d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def has_empty_cells(self, board):\n",
    "        result = True\n",
    "\n",
    "        if np.any(board == 0) == False:\n",
    "            result = False\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def find_empty_cells(self, board):\n",
    "        empty_cells = []\n",
    "\n",
    "        if self.has_empty_cells(board) == True:\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    if board[i,j] == 0:\n",
    "                        empty_cells.append((i,j))\n",
    "\n",
    "        return empty_cells\n",
    "    \n",
    "    def get_reward(self, board):\n",
    "        reward = 0\n",
    "        if self.has_agent_won(board) == True:\n",
    "            reward = 10\n",
    "        elif self.has_enemy_won(board) == True:\n",
    "            reward = -10\n",
    "        elif self.has_game_drawn(board) == True:\n",
    "            reward = 0\n",
    "        else:\n",
    "            reward = 1\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def has_agent_won(self, board):\n",
    "        result = False\n",
    "\n",
    "        row_wise_sum = np.sum(board, axis=0)\n",
    "        col_wise_sum = np.sum(board, axis=1)\n",
    "        main_diag_sum = np.sum([board[i,i] for i in range(3)])\n",
    "        off_diag_sum = np.sum([board[i,2-i] for i in range(3)])\n",
    "\n",
    "        if np.any(row_wise_sum == 3) or np.any(col_wise_sum == 3) or main_diag_sum == 3 or off_diag_sum == 3:\n",
    "            result = True\n",
    "\n",
    "        return result\n",
    "\n",
    "    def has_enemy_won(self, board):\n",
    "        result = False\n",
    "\n",
    "        row_wise_sum = np.sum(board, axis=0)\n",
    "        col_wise_sum = np.sum(board, axis=1)\n",
    "        main_diag_sum = np.sum([board[i,i] for i in range(3)])\n",
    "        off_diag_sum = np.sum([board[i,2-i] for i in range(3)])\n",
    "\n",
    "        if np.any(row_wise_sum == -3) or np.any(col_wise_sum == -3) or main_diag_sum == -3 or off_diag_sum == -3:\n",
    "            result = True\n",
    "\n",
    "        return result\n",
    "\n",
    "    def has_game_drawn(self, board):\n",
    "        result = False\n",
    "\n",
    "        if self.has_empty_cells(board) == False and self.has_agent_won(board) == False and self.has_enemy_won(board) == False:\n",
    "            result = True\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def has_game_end(self, board):\n",
    "        result = False\n",
    "\n",
    "        if self.has_agent_won(board) == True or self.has_enemy_won(board) == True or self.has_game_drawn(board) == True:\n",
    "            result = True\n",
    "\n",
    "        return result\n",
    "    \n",
    "    # returns the updated board state and a bool specifying whether enemy moved or not\n",
    "    def enemy_move(self, board, empty_cell):\n",
    "        has_enemy_moved = False\n",
    "\n",
    "#         if self.has_empty_cells(board) == False:\n",
    "#             return board, has_enemy_moved\n",
    "\n",
    "        # find empty cells\n",
    "#         empty_cells = self.find_empty_cells(board)\n",
    "#         num_empty_cells = len(empty_cells)\n",
    "\n",
    "        # generate a random number between [0, num_empty_cells-1] (both inclusive)\n",
    "#         rand_num = np.random.randint(0, num_empty_cells)\n",
    "\n",
    "#         enemy_move_pos = empty_cells[rand_num]\n",
    "\n",
    "        board[empty_cell[0], empty_cell[1]] = -1\n",
    "        has_enemy_moved = True\n",
    "\n",
    "        return has_enemy_moved, board\n",
    "    \n",
    "    # returns the updated board state and a bool specifying whether enemy moved or not\n",
    "    def agent_move(self, board, empty_cell):\n",
    "        has_agent_moved = False\n",
    "\n",
    "        board[empty_cell[0], empty_cell[1]] = 1\n",
    "        has_agent_moved = True\n",
    "\n",
    "        return has_agent_moved, board\n",
    "\n",
    "    def compute_reward_to_go(self, traj, gamma=0.9):\n",
    "        traj_len = len(traj)\n",
    "        reward_to_go = []\n",
    "\n",
    "        for i in range(traj_len):\n",
    "            temp_sum = 0\n",
    "            for j in range(i, traj_len):\n",
    "                temp_sum = temp_sum + pow(gamma, j-i) * traj[j].reward\n",
    "\n",
    "            reward_to_go.append(temp_sum)\n",
    "\n",
    "        return reward_to_go\n",
    "\n",
    "    def convert_mat_to_string(self, board):\n",
    "        result = ''\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if board[i,j] == 0:\n",
    "                    result = result + '-'\n",
    "                elif board[i,j] == 1:\n",
    "                    result = result + 'o'\n",
    "                elif board[i,j] == -1:\n",
    "                    result = result + 'x'\n",
    "        return result\n",
    "\n",
    "    def convert_string_to_mat(self, mystring):\n",
    "        board = np.zeros((3,3))\n",
    "        itr = 0\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if mystring[itr] == '-':    \n",
    "                    board[i,j] = 0\n",
    "                elif mystring[itr] == 'o':\n",
    "                    board[i,j] = 1\n",
    "                elif mystring[itr] == 'x':    \n",
    "                    board[i,j] = -1\n",
    "                itr += 1\n",
    "        return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "918d9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sim_obj = Simulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edd4cfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oxox-----\n",
      "[[ 1. -1.  1.]\n",
      " [-1.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "state = np.array([[1,-1,1],[-1,0,0],[0,0,0]])\n",
    "a = global_sim_obj.convert_mat_to_string(state)\n",
    "print(a)\n",
    "print(global_sim_obj.convert_string_to_mat(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b1ccb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state, player_type=0):\n",
    "        self.state = np.copy(state)      # 3x3 matrix representing the board state\n",
    "\n",
    "        self.children = []              # to store a list of (action, child_node) tuples\n",
    "\n",
    "        self.player_type = player_type\n",
    "        self.reward = global_sim_obj.get_reward(self.state)\n",
    "        self.values = 0\n",
    "        self.nodeID = None\n",
    "\n",
    "    def is_terminal(self):\n",
    "        if not self.children:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d14fc15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self, root_state):\n",
    "        self.root = Node(root_state, ENEMY)\n",
    "#         self.simulator = Simulator()\n",
    "        self.state_list = []\n",
    "        self.node_list = []\n",
    "\n",
    "    def is_node_present(self, root_node, node_state):\n",
    "        if np.any(node_state - self.root.state) == False:\n",
    "            print(\"This should be printed once\")\n",
    "            return False, None\n",
    "        \n",
    "        child_list = root_node.children\n",
    "\n",
    "        if len(child_list) != 0:\n",
    "            for child in child_list:\n",
    "                child_node = child[1]\n",
    "                if np.any(node_state - child_node.state) == False:\n",
    "                    return True, child_node\n",
    "                else:\n",
    "                    if_present, return_node = self.is_node_present(child_node, node_state)\n",
    "                    if if_present == True:\n",
    "                        return True, return_node\n",
    "        \n",
    "        return False, None          \n",
    "        \n",
    "    def build_tree(self, node, player_type, agent_action=None):\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        \n",
    "        if global_sim_obj.has_game_end(np.copy(node.state)) == True:\n",
    "            return\n",
    "            \n",
    "        if player_type == ENEMY:\n",
    "            init_Q_state = np.copy(node.state)\n",
    "            \n",
    "            if global_sim_obj.has_empty_cells(init_Q_state) == True:\n",
    "                empty_cells = global_sim_obj.find_empty_cells(init_Q_state)\n",
    "                num_empty_cells = len(empty_cells)\n",
    "                \n",
    "                for i in range(num_empty_cells):\n",
    "                    has_enemy_moved, modified_board_state = global_sim_obj.enemy_move(np.copy(init_Q_state), empty_cells[i])\n",
    "                    assert(np.sum(modified_board_state) == -1)\n",
    "                    \n",
    "                    if has_enemy_moved == True:\n",
    "#                         present, child_node = self.is_node_present(self.root, np.copy(modified_board_state))\n",
    "                        present = False\n",
    "                        \n",
    "                        if present:\n",
    "                            node.children.append((agent_action, child_node))\n",
    "                        else:\n",
    "                            global num_tree_nodes\n",
    "                            num_tree_nodes += 1\n",
    "                            if (num_tree_nodes % 10000 == 0):\n",
    "                                print(\"Curr Nodes: \", num_tree_nodes)\n",
    "\n",
    "                            child_node = Node(modified_board_state)\n",
    "                            node.children.append((agent_action, child_node))\n",
    "\n",
    "                            self.state_list.append(np.copy(modified_board_state))\n",
    "                            self.node_list.append(child_node)\n",
    "\n",
    "                            if global_sim_obj.has_game_end(modified_board_state) == True:\n",
    "                                pass\n",
    "                            else:\n",
    "                                self.build_tree(child_node, player_type=AGENT)\n",
    "\n",
    "        elif player_type == AGENT:\n",
    "            init_board_state = np.copy(node.state)\n",
    "            \n",
    "            if global_sim_obj.has_empty_cells(init_board_state) == True:\n",
    "                empty_cells = global_sim_obj.find_empty_cells(init_board_state)\n",
    "                num_empty_cells = len(empty_cells)\n",
    "\n",
    "                for i in range(num_empty_cells):\n",
    "                    # agent will take an action to get to Q-state\n",
    "                    agent_action = empty_cells[i]\n",
    "                    has_agent_moved, modified_Q_state = global_sim_obj.agent_move(np.copy(init_board_state), agent_action)\n",
    "                    assert(np.sum(modified_Q_state) == 0)\n",
    "                    \n",
    "                    if has_agent_moved == True:\n",
    "\n",
    "                        if global_sim_obj.has_game_end(modified_Q_state) == True:\n",
    "                            if global_sim_obj.has_agent_won(modified_Q_state) == True:\n",
    "                                child_node = Node(modified_Q_state)\n",
    "                                node.children.append((agent_action, child_node))\n",
    "                        else:\n",
    "                            node.state = np.copy(modified_Q_state)\n",
    "                            self.build_tree(node, player_type=ENEMY, agent_action=agent_action)\n",
    "                            node.state = np.copy(init_board_state)\n",
    "    \n",
    "    def print_trajectory(self):\n",
    "        traj = []\n",
    "        continue_loop = True\n",
    "        tree_node = self.root\n",
    "\n",
    "        while continue_loop:\n",
    "            traj.append(tree_node)\n",
    "            node_state = tree_node.state\n",
    "\n",
    "            if tree_node.is_terminal() == False:\n",
    "                child_list = tree_node.children\n",
    "                num_child = len(child_list)\n",
    "\n",
    "                child_element = child_list[np.random.randint(0, num_child)]\n",
    "\n",
    "                tree_node = child_element[1]\n",
    "            else:\n",
    "                if (global_sim_obj.has_agent_won(tree_node.state) == True):\n",
    "                    print(\"Agent Won !!!\")\n",
    "                elif (global_sim_obj.has_enemy_won(tree_node.state) == True):\n",
    "                    print(\"Enemy Won !!!\")\n",
    "                elif (global_sim_obj.has_game_drawn(tree_node.state) == True):\n",
    "                    print(\"Game Drawn !!!\")\n",
    "                else:\n",
    "                    print(\"Something is wrong\")\n",
    "\n",
    "                continue_loop = False\n",
    "        \n",
    "        reward_to_go = global_sim_obj.compute_reward_to_go(traj)\n",
    "        traj_len = len(traj)\n",
    "        for j in range(traj_len):\n",
    "            print(traj[j].state, \",  R(s_i) = \", global_sim_obj.get_reward(traj[j].state), \" G(s_i) = \", round(reward_to_go[j], 2), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5ebc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT, ENEMY = 0, 1\n",
    "game_obj = TicTacToe(np.zeros((3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25b1ba76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curr Nodes:  10000\n",
      "Curr Nodes:  20000\n",
      "Curr Nodes:  30000\n",
      "Curr Nodes:  40000\n",
      "Curr Nodes:  50000\n",
      "Curr Nodes:  60000\n",
      "Curr Nodes:  70000\n",
      "Curr Nodes:  80000\n",
      "Curr Nodes:  90000\n",
      "Curr Nodes:  100000\n",
      "Curr Nodes:  110000\n",
      "Curr Nodes:  120000\n",
      "Curr Nodes:  130000\n",
      "Curr Nodes:  140000\n",
      "Curr Nodes:  150000\n",
      "Curr Nodes:  160000\n",
      "Curr Nodes:  170000\n",
      "Curr Nodes:  180000\n",
      "Curr Nodes:  190000\n",
      "Curr Nodes:  200000\n",
      "Curr Nodes:  210000\n",
      "Curr Nodes:  220000\n",
      "Curr Nodes:  230000\n",
      "Curr Nodes:  240000\n",
      "Curr Nodes:  250000\n",
      "Curr Nodes:  260000\n",
      "Curr Nodes:  270000\n",
      "Curr Nodes:  280000\n",
      "Curr Nodes:  290000\n"
     ]
    }
   ],
   "source": [
    "num_tree_nodes = 0\n",
    "game_obj.build_tree(None, player_type=ENEMY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "854db9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory - 1\n",
      "Agent Won !!!\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[ 0. -1.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[ 0. -1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0. -1.  0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[ 1. -1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0. -1. -1.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[ 1. -1. -1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0. -1. -1.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[ 1. -1. -1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 0. -1. -1.]] ,  R(s_i) =  10  G(s_i) =  10.0 \n",
      "\n",
      "\n",
      "\n",
      "Trajectory - 2\n",
      "Agent Won !!!\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[-1.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[-1.  0.  0.]\n",
      " [ 0.  0. -1.]\n",
      " [ 0.  1.  0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[-1. -1.  0.]\n",
      " [ 0.  0. -1.]\n",
      " [ 1.  1.  0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[-1. -1.  0.]\n",
      " [ 0.  0. -1.]\n",
      " [ 1.  1.  1.]] ,  R(s_i) =  10  G(s_i) =  10.0 \n",
      "\n",
      "\n",
      "\n",
      "Trajectory - 3\n",
      "Enemy Won !!!\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] ,  R(s_i) =  1  G(s_i) =  -4.58 \n",
      "\n",
      "[[ 0.  0.  0.]\n",
      " [-1.  0.  0.]\n",
      " [ 0.  0.  0.]] ,  R(s_i) =  1  G(s_i) =  -6.2 \n",
      "\n",
      "[[ 0.  0.  0.]\n",
      " [-1.  0. -1.]\n",
      " [ 0.  0.  1.]] ,  R(s_i) =  1  G(s_i) =  -8.0 \n",
      "\n",
      "[[ 0.  0.  0.]\n",
      " [-1. -1. -1.]\n",
      " [ 1.  0.  1.]] ,  R(s_i) =  -10  G(s_i) =  -10.0 \n",
      "\n",
      "\n",
      "\n",
      "Trajectory - 4\n",
      "Agent Won !!!\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0. -1.  0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  0. -1.]\n",
      " [ 0. -1.  0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[ 1.  0.  1.]\n",
      " [ 0.  0. -1.]\n",
      " [-1. -1.  0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[ 1.  1.  1.]\n",
      " [ 0.  0. -1.]\n",
      " [-1. -1.  0.]] ,  R(s_i) =  10  G(s_i) =  10.0 \n",
      "\n",
      "\n",
      "\n",
      "Trajectory - 5\n",
      "Agent Won !!!\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[ 0. -1.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[ 0. -1.  1.]\n",
      " [-1.  0.  0.]\n",
      " [ 0.  0.  0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[ 0. -1.  1.]\n",
      " [-1.  0.  1.]\n",
      " [ 0. -1.  0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[-1. -1.  1.]\n",
      " [-1.  1.  1.]\n",
      " [ 0. -1.  0.]] ,  R(s_i) =  1  G(s_i) =  10.0 \n",
      "\n",
      "[[-1. -1.  1.]\n",
      " [-1.  1.  1.]\n",
      " [ 1. -1.  0.]] ,  R(s_i) =  10  G(s_i) =  10.0 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 5 random trajectory\n",
    "for i in range(5):\n",
    "    print(\"Trajectory -\", (i+1))\n",
    "    game_obj.print_trajectory()\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bacb038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of states in the tree:  291681\n",
      "Total number of nodes in the tree:  291681\n",
      "Iteration:  0 / 291681 , # Unique States:  0\n",
      "Iteration:  10000 / 291681 , # Unique States:  716\n",
      "Iteration:  20000 / 291681 , # Unique States:  963\n",
      "Iteration:  30000 / 291681 , # Unique States:  1027\n",
      "Iteration:  40000 / 291681 , # Unique States:  1466\n",
      "Iteration:  50000 / 291681 , # Unique States:  1652\n",
      "Iteration:  60000 / 291681 , # Unique States:  1724\n",
      "Iteration:  70000 / 291681 , # Unique States:  1937\n",
      "Iteration:  80000 / 291681 , # Unique States:  2134\n",
      "Iteration:  90000 / 291681 , # Unique States:  2180\n",
      "Iteration:  100000 / 291681 , # Unique States:  2288\n",
      "Iteration:  110000 / 291681 , # Unique States:  2419\n",
      "Iteration:  120000 / 291681 , # Unique States:  2448\n",
      "Iteration:  130000 / 291681 , # Unique States:  2469\n",
      "Iteration:  140000 / 291681 , # Unique States:  2572\n",
      "Iteration:  150000 / 291681 , # Unique States:  2612\n",
      "Iteration:  160000 / 291681 , # Unique States:  2622\n",
      "Iteration:  170000 / 291681 , # Unique States:  2666\n",
      "Iteration:  180000 / 291681 , # Unique States:  2688\n",
      "Iteration:  190000 / 291681 , # Unique States:  2698\n",
      "Iteration:  200000 / 291681 , # Unique States:  2708\n",
      "Iteration:  210000 / 291681 , # Unique States:  2720\n",
      "Iteration:  220000 / 291681 , # Unique States:  2728\n",
      "Iteration:  230000 / 291681 , # Unique States:  2732\n",
      "Iteration:  240000 / 291681 , # Unique States:  2734\n",
      "Iteration:  250000 / 291681 , # Unique States:  2737\n",
      "Iteration:  260000 / 291681 , # Unique States:  2739\n",
      "Iteration:  270000 / 291681 , # Unique States:  2739\n",
      "Iteration:  280000 / 291681 , # Unique States:  2739\n",
      "Iteration:  290000 / 291681 , # Unique States:  2739\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of states in the tree: \", len(game_obj.state_list))\n",
    "print(\"Total number of nodes in the tree: \", len(game_obj.node_list))\n",
    "\n",
    "num_repeated_states = len(game_obj.state_list)\n",
    "unique_state_list = []\n",
    "unique_node_list = []\n",
    "\n",
    "for i in range(num_repeated_states):\n",
    "    include = True\n",
    "    num_unique_states = len(unique_state_list)\n",
    "\n",
    "    if (i % 10000 == 0):\n",
    "        print(\"Iteration: \", i, '/', num_repeated_states, ', # Unique States: ', num_unique_states)\n",
    "    \n",
    "    for j in range(num_unique_states):\n",
    "        if np.any(game_obj.state_list[i] - unique_state_list[j]) == False:\n",
    "            include = False\n",
    "            break\n",
    "    \n",
    "    if include:\n",
    "        unique_state_list.append(game_obj.state_list[i])\n",
    "        unique_node_list.append(game_obj.node_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c16be506",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_states = len(unique_state_list)\n",
    "for i in range(num_unique_states):\n",
    "    assert(not np.any(unique_state_list[i] - unique_node_list[i].state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "597a07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(state_list, node_list, gamma=0.9, epsilon=1e-1):\n",
    "    delta_thresh = epsilon * (1-gamma) / gamma\n",
    "\n",
    "    num_states = len(state_list)\n",
    "    new_values_list = np.zeros((num_states, 1))\n",
    "    curr_values_list = np.zeros((num_states, 1))\n",
    "\n",
    "    has_converged = False\n",
    "\n",
    "    itr_count = 0\n",
    "    while has_converged == False:\n",
    "        curr_values_list = np.copy(new_values_list)\n",
    "        delta = 0\n",
    "        \n",
    "        for i in range(num_states):\n",
    "            board_state = state_list[i]\n",
    "            state_reward = game_obj.simulator.get_reward(board_state)\n",
    "            child_list = node_list[i].children\n",
    "            num_child = len(child_list)\n",
    "            assert(np.any(board_state - node_list[i].state) == False)\n",
    "#             print(\"Assertion successful !!!\")\n",
    "#             print(\"State: \", board_state)\n",
    "#             print(\"Num child: \", num_child)\n",
    "            \n",
    "            if num_child > 0:\n",
    "                child_dict = {}\n",
    "                \n",
    "                for j in range(num_child):\n",
    "                    child_obj = child_list[j]    # (action, child node)\n",
    "                    child_parent_action = child_obj[0]\n",
    "                    x,y = child_parent_action\n",
    "\n",
    "                    if (x,y) not in child_dict:\n",
    "                        child_dict[(x,y)] = []\n",
    "#                         print(\"X & Y: \", x, y)\n",
    "                    \n",
    "                    child_node = child_obj[1]\n",
    "#                     print(\"Child State:\", child_node.state)\n",
    "                    child_dict[(x,y)].append(child_node)\n",
    "                    \n",
    "                actions = list(child_dict.keys())\n",
    "                num_actions = len(actions)\n",
    "#                 print(\"Actions: \", actions, \"Num Actions: \", num_actions)\n",
    "                \n",
    "                prob = {}\n",
    "                for j in range(num_actions):\n",
    "                    action = actions[j]\n",
    "                    x, y = action\n",
    "                    num_child_per_action = len(child_dict[(x,y)])\n",
    "                    prob[(x,y)] = 1 / num_child_per_action\n",
    "                \n",
    "#                 print(\"Probability: \", prob)\n",
    "                \n",
    "                max_expected_val = -math.inf\n",
    "                for j in range(num_actions):\n",
    "                    action = actions[j]\n",
    "                    x,y = action\n",
    "                    pot_states_list = child_dict[(x,y)]\n",
    "                    num_pot_states = len(pot_states_list)\n",
    "                    \n",
    "                    expected_val = 0\n",
    "                    for k in range(num_pot_states):\n",
    "                        pot_state = pot_states_list[k].state\n",
    "                        # search the index of this state in the state list\n",
    "                        \n",
    "                        pot_idx = None\n",
    "                        for itr in range(num_states):\n",
    "#                             print(\"This is USA: \", state_list[itr])\n",
    "#                             print(\"This is India: \", pot_state)\n",
    "                            if (np.any(state_list[itr] - pot_state) == False):\n",
    "                                pot_idx = itr\n",
    "                                break\n",
    "                        \n",
    "                        expected_val = expected_val + prob[(x,y)] * curr_values_list[pot_idx,0]\n",
    "                    \n",
    "                    if expected_val > max_expected_val:\n",
    "                        max_expected_val = expected_val\n",
    "                \n",
    "                new_values_list[i,0] = state_reward + gamma * max_expected_val\n",
    "            else:\n",
    "                new_values_list[i,0] = state_reward\n",
    "        \n",
    "        delta = np.max(np.abs(new_values_list - curr_values_list))\n",
    "        \n",
    "        if (delta < delta_thresh):\n",
    "            print(\"CONVERGED !!!\")\n",
    "            has_converged = True\n",
    "        \n",
    "        itr_count += 1\n",
    "        print(\"Iteration -\", itr_count, \" Delta: \", delta)\n",
    "\n",
    "    return new_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc6339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - 1  Delta:  10.0\n",
      "Iteration - 2  Delta:  9.0\n"
     ]
    }
   ],
   "source": [
    "value_iteration(game_obj.state_list, game_obj.node_list)\n",
    "# value_iteration(unique_state_list, unique_node_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
